{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def information(p):\n",
    "    return -np.log2(p + (p==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 19: Transinformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gegeben ist der nachfolgend dargestellte Übertragungskanal mit $\\Omega_X = \\{0, 1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kanal](figures/A19/Channel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgrund der additven, von $X$ unabhängigen Störung ist die Übertragung fehlerhaft. Um die statistischen Eigenschaften der Störung zu ermitteln, werden zunächst sehr viele Einsen gesendet. Am Empfänger beobachtet man in $40\\, \\%$ der Fälle $y=1$ und in $60\\, \\%$ der Fälle $y=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.1:\n",
    "Ermitteln sie die Mengen $\\Omega_N$ und $\\Omega_Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da nur Einsen übertragen werden und die Störung additiv ist, ergibt sich:\n",
    "\n",
    "\\begin{align}\n",
    "    & &X + N &= Y \\\\\n",
    "    &1)&\\quad 1 + n &= 1 &\\quad& \\Rightarrow n = 0 \\\\\n",
    "    &2)&\\quad 1 + n &= 0 &\\quad& \\Rightarrow n = {-}1\n",
    "\\end{align}\n",
    "\n",
    "Damit ist $\\Omega_N = \\{{-}1, 0 \\}$ festgelegt. Für den Fall $X=0$ ergibt sich, da die Störung unabhängig von $X$ ist:\n",
    "\n",
    "\\begin{align}\n",
    "    &1)&\\quad 0 + 0 &= 0 &\\quad& \\Rightarrow y = 0 \\\\\n",
    "    &2)&\\quad 0 + ({-}1) &= {-}1 &\\quad& \\Rightarrow y = {-}1\n",
    "\\end{align}\n",
    "\n",
    "Damit steht $\\Omega_Y = \\{{-1},0,1\\}$ fest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.2:\n",
    "\n",
    "Bestimmen sie alle bedingten Wahrscheinlichkeiten $\\mathrm{Pr}_{Y|X}(y|x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die bedingten Wahrscheinlichkeiten hängen bei gegebenem $X$ nur von $N$ ab. Da $N$ unabhängig von $X$ ist, muss gelten:\n",
    "\n",
    "\\begin{align}\n",
    "    &\\mathrm{Pr}_{Y|X}(y=0|x=1)& &= \\mathrm{Pr}(n={-}1) &&= \\mathrm{Pr}_{Y|X}(y={-}1|x=0) &&= 0{,}6 \\\\\n",
    "    &\\mathrm{Pr}_{Y|X}(y=1|x=1)& &= \\mathrm{Pr}(n=0) &&= \\mathrm{Pr}_{Y|X}(y=0|x=0) &&= 0{,}4 \\\\\n",
    "    &\\mathrm{Pr}_{Y|X}(y={-}1|x=1)& &= \\mathrm{Pr}(n \\not\\in \\Omega_N) & &= \\mathrm{Pr}_{Y|X}(y=1|x=0) &&= 0\n",
    "\\end{align}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|$\\mathrm{Pr}_{Y \\mid X}(y {\\mid} x)$|$y={-}1$|$y=0$|$y=1$|\n",
    "|:-----------------------------|:--------:|:--------:|:--------:|\n",
    "|     $x = 0$                  | $0{,}6$  | $0{,}4$  | $0    $  |\n",
    "|     $x = 1$                  | $0    $  | $0{,}6$  | $0{,}4$  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_y_given_x = np.array([\n",
    "        [0.6, 0.4, 0],\n",
    "        [0, 0.6, 0.4]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ab jetzt werden Einsen und Nullen mit gleicher Wahrscheinlichkeit gesendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.3:\n",
    "Geben sie alle Verbundwahrscheinlichkeiten $\\mathrm{Pr}_{X,Y}(x,y)$ an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Angabe gibt die A-Priori-Wahrscheinlichkeiten für die Werte von $X$ vor:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{Pr}_X(x=0) = \\mathrm{Pr}_X(x=0) = \\frac{1}{2}\n",
    "\\end{align}\n",
    "\n",
    "Die Verbundwahrscheinlichkeiten können über die umgestellte Definition der bedingten Wahrscheinlichkeit berechnet werden:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{Pr}_{X,Y}(x,y) = \\mathrm{Pr}_{Y|X}(y,x) \\cdot \\mathrm{Pr}_X(x)\n",
    "\\end{align}\n",
    "\n",
    "Die Zellen der Tabelle müssen also nur halbiert werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|$\\mathrm{Pr}_{X,Y}(x,y)$|$y={-}1$|$y=0$|$y=1$|\n",
    "|:-----------------------------|:--------:|:--------:|:--------:|\n",
    "|     $x = 0$                  | $0{,}3$  | $0{,}2$  | $0    $  |\n",
    "|     $x = 1$                  | $0    $  | $0{,}3$  | $0{,}2$  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3,  0.2,  0. ],\n",
       "       [ 0. ,  0.3,  0.2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_x = np.array([0.5, 0.5])\n",
    "prob_xy = prob_x[:,None] * prob_y_given_x\n",
    "prob_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.4:\n",
    "Mit welcher Wahrscheinlichkeit treten die Zeichen am Ausgang des Kanals auf?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier muss marginalisiert werden:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{Pr}_Y(y) = \\sum_{x \\in \\Omega_X} \\mathrm{Pr}_{X,Y}(x,y)\n",
    "\\end{align}\n",
    "\n",
    "Es können also einfach die Zellen der Tabelle entlang jeder Spalte aufsummiert werden (daher stammt übrigens auch der Name Marginal- oder Randwahrscheinlichkeit):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                              |$y={-}1\\quad$|$y=0\\quad$|$y=1\\quad$|\n",
    "|:-----------------------------|:--------:|:--------:|:--------:|\n",
    "|$\\mathrm{Pr}_{Y}(y)\\quad$ | $0{,}3$  | $0{,}5$  | $0{,}2$  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3,  0.5,  0.2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_y = prob_xy.sum(axis=0)\n",
    "prob_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.5:\n",
    "Wie hoch ist der Informationsverlust bei der Übertragung über den Kanal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Informationsverlust, auch **Äquivokation** genannt, ist die Unsicherheit im Eingang $X$, die verbleibt, wenn der Ausgang $Y$ bekannt ist; es its also die **bedingte Entropie von $X$ gegeben $Y$**. Folgendes Bild von **Wikipedia** kann hilfreich sein:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Verhältnisse im Kanal](https://upload.wikimedia.org/wikipedia/commons/c/cf/Entroy_XY.png)\n",
    "\n",
    "[Link zur Quelle; Grafik von Nutzer Akribix, mit Lizenz Creative Commons CC-BY-SA-2.5](https://commons.wikimedia.org/wiki/File:Entroy_XY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dazu muss die bedingte Wahrscheinlichkeit von $X$ gegeben $Y$ bestimmt werden. Alternativ kann auch die Differenz zwischen Verbundentropie und Entropie von $X$ verwendet werden:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{H}(X|Y) &= \\mathrm{E}_{X,Y}\\left[ -\\log_2\\left(\\mathrm{Pr}_{X|Y}(X|Y)\\right) \\right] \\\\\n",
    "                    &= \\mathrm{E}_{X,Y}\\left[ -\\log_2\\left(\\frac{\\mathrm{Pr}_{X,Y}(X,Y)}{\\mathrm{Pr}_{Y}(Y)}\\right) \\right] \\\\\n",
    "                    &= \\mathrm{H}(X,Y) - \\mathrm{H}(Y) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verbundentropie ist\n",
    "\n",
    "\\begin{align}\n",
    "                   \\mathrm{H}(X,Y) &= \\sum_{x \\in \\Omega_X} \\sum_{y \\in \\Omega_Y} - \\log_2\\left(\\mathrm{Pr}_{X,Y}(x,y)\\right)\\mathrm{Pr}_{X,Y}(x,y) \\\\\n",
    "                    &= -2 \\cdot \\left( \\log_2(0{,}3) \\cdot 0{,}3 + \\log_2(0{,}2) \\cdot 0{,}2 \\right) \\\\\n",
    "                    &= 1{,}9710 \\, \\mathrm{Bit}/\\mathrm{Symbolpaar}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(X,Y) = 1.9710 Bits/Symbolpaar\n"
     ]
    }
   ],
   "source": [
    "H_xy = (information(prob_xy) * prob_xy).sum()\n",
    "print(\"H(X,Y) = {:1.4f} Bits/Symbolpaar\".format(H_xy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "und die Entropie von Y ist\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{H}(Y) &= \\sum_{y \\in \\Omega_Y} - \\log_2\\left(\\mathrm{Pr}_Y(y)\\right)\\mathrm{Pr}_{Y}(y) \\\\\n",
    "        &= -\\log_2(0{,}3) \\cdot 0{,}3 - \\log_2(0{,}5) \\cdot 0{,}5 -\\log_2(0{,}2) \\cdot 0{,}2 \\\\\n",
    "        &= 1{,}4855 \\, \\mathrm{Bit}/\\mathrm{Symbol}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(Y) = 1.4855 Bits/Symbol\n"
     ]
    }
   ],
   "source": [
    "H_y = prob_y @ information(prob_y)\n",
    "print(\"H(Y) = {:1.4f} Bits/Symbol\".format(H_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also ist die **Äquivokation**:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{H}(X|Y) &= \\mathrm{H}(X,Y) - \\mathrm{H}(Y) \\\\\n",
    "            &= 1{,}9710 \\, \\mathrm{Bit}/\\mathrm{Symbolpaar} - 1{,}4855 \\, \\mathrm{Bit}/\\mathrm{Symbol} \\\\\n",
    "            &= 0{,}4855 \\, \\mathrm{Bit}/\\mathrm{Symbol}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(X|Y) = 0.4855 Bits/Symbol\n"
     ]
    }
   ],
   "source": [
    "H_x_given_y = H_xy - H_y\n",
    "print(\"H(X|Y) = {:1.4f} Bits/Symbol\".format(H_x_given_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.6:\n",
    "Welche Transinformation gelangt über den Kanal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Transinformation kann als Differenz der Unsicherheit des Eingangs $X$ vor und nach der Beobachtung von $Y$ berechnet werden:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{I}(X;Y) = \\mathrm{H}(X) - \\mathrm{H}(X|Y)\n",
    "\\end{align}\n",
    "\n",
    "Da die bedingte Entropie von $X$ gegeben $Y$ schon bekannt ist, muss nur noch die Entropie von $X$ berechnet werden. Da $X$ aus dem gleichverteilten, zweiwertigen Alphabet $\\Omega_X$ stammt, ist die Entropie leicht berechenbar:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{H}(X) = \\log_2|\\Omega_X| = \\log_2(2) = 1\\, \\mathrm{Bit}/\\mathrm{Symbol}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(X) = 1.0000 Bits/Symbol\n"
     ]
    }
   ],
   "source": [
    "H_x = information(prob_x) @ prob_x\n",
    "print(\"H(X) = {:1.4f} Bits/Symbol\".format(H_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Transinformation kann nun einfach als Differenz bestimmt werden:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{I}(X;Y) &= \\mathrm{H}(X) - \\mathrm{H}(X|Y) \\\\\n",
    "        &= 1\\, \\mathrm{Bit}/\\mathrm{Symbol} - 0{,}4855 \\, \\mathrm{Bit}/\\mathrm{Symbol} \\\\\n",
    "        &= 0{,}5145\\, \\mathrm{Bit}/\\mathrm{Symbol}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I(X;Y) = I(Y;X) = 0.5145 Bits/Symbol\n"
     ]
    }
   ],
   "source": [
    "mutual_information_x_y = H_x - H_x_given_y\n",
    "print(\"I(X;Y) = I(Y;X) = {:1.4f} Bits/Symbol\".format(mutual_information_x_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die Zerlegung der Äquivokation und der Fehlinformation ist übrigens auch hier die Symmetrie der Transinformation beweisbar:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{I}(X;Y) = \\mathrm{H}(X) - \\mathrm{H}(X|Y) \n",
    "        = \\mathrm{H}(X) - \\left( \\mathrm{H}(X,Y) - \\mathrm{H}(Y)\\right) \n",
    "        = \\mathrm{H}(X) + \\mathrm{H}(Y) - \\mathrm{H}(X,Y) \\\\ \n",
    "    \\mathrm{I}(Y;X) = \\mathrm{H}(Y) - \\mathrm{H}(Y|X) \n",
    "        = \\mathrm{H}(Y) - \\left( \\mathrm{H}(X,Y) - \\mathrm{H}(X)\\right) \n",
    "        = \\mathrm{H}(Y) + \\mathrm{H}(X) - \\mathrm{H}(X,Y) \\\\ \n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
